{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "import os, shutil, time, pdb, random\n",
    "import scipy.stats as stats \n",
    "import scipy\n",
    "\n",
    "from math import pi\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from importlib import reload\n",
    "from models import *\n",
    "from utils import *\n",
    "from runmanager import *\n",
    "from experiment import *\n",
    "from plot_utils import *\n",
    "from preprocessing_utils import *\n",
    "from analysis_seasonal import * \n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc_file_defaults()\n",
    "%matplotlib inline\n",
    "\n",
    "import CONFIG\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = CONFIG.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataPreprocessing(train_path=CONFIG.TRAIN_PATH, start=CONFIG.start, end=CONFIG.end, \n",
    "                add_yesterday = False, \n",
    "                basin_filter = None, \n",
    "                split_bias_corrected_only = False, \n",
    "                filter_incomplete_years = False, \n",
    "                include_non_bc_stations = True, \n",
    "                split_by = 'station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into held out sets for K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split_stations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n",
      "/users/marron31/repos/upper-indus-prec-bc/preprocessing_utils.py:205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  QM_df = QM_df.append(QM_data[s])\n"
     ]
    }
   ],
   "source": [
    "# CONFIG.predictors.append('obs_yesterday')\n",
    "data.input_data(CONFIG.predictors, CONFIG.predictand, sort_by_quantile=CONFIG.sort_by_quantile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Run: Train model with different hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>decision_loss</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>likelihood_fn</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>k</th>\n",
       "      <th>model_arch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>1.896931</td>\n",
       "      <td>2.332096</td>\n",
       "      <td>1.896931</td>\n",
       "      <td>1.131365</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.030030</td>\n",
       "      <td>1.959911</td>\n",
       "      <td>2.541596</td>\n",
       "      <td>1.959911</td>\n",
       "      <td>1.059794</td>\n",
       "      <td>2.405536</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.079324</td>\n",
       "      <td>1.995050</td>\n",
       "      <td>2.690020</td>\n",
       "      <td>1.995050</td>\n",
       "      <td>1.011632</td>\n",
       "      <td>3.446845</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.221408</td>\n",
       "      <td>1.663102</td>\n",
       "      <td>2.928188</td>\n",
       "      <td>1.663102</td>\n",
       "      <td>1.027108</td>\n",
       "      <td>4.499626</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.168919</td>\n",
       "      <td>2.618845</td>\n",
       "      <td>3.449633</td>\n",
       "      <td>2.618845</td>\n",
       "      <td>1.013980</td>\n",
       "      <td>5.555817</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.415992</td>\n",
       "      <td>2.093991</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.093991</td>\n",
       "      <td>1.010513</td>\n",
       "      <td>6.606770</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.626374</td>\n",
       "      <td>1.941715</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.941715</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>7.614655</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.603916</td>\n",
       "      <td>1.938419</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.938419</td>\n",
       "      <td>1.011184</td>\n",
       "      <td>8.656074</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.306061</td>\n",
       "      <td>1.540836</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.540836</td>\n",
       "      <td>1.022666</td>\n",
       "      <td>9.712116</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.133800</td>\n",
       "      <td>1.845853</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.845853</td>\n",
       "      <td>1.008887</td>\n",
       "      <td>10.773441</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.560200</td>\n",
       "      <td>1.861353</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.861353</td>\n",
       "      <td>1.018849</td>\n",
       "      <td>11.826798</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.818080</td>\n",
       "      <td>1.967659</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.967659</td>\n",
       "      <td>1.022380</td>\n",
       "      <td>12.879641</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.418223</td>\n",
       "      <td>1.500050</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.500050</td>\n",
       "      <td>1.007361</td>\n",
       "      <td>13.923045</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.228807</td>\n",
       "      <td>1.875615</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.875615</td>\n",
       "      <td>1.016274</td>\n",
       "      <td>14.976663</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.618656</td>\n",
       "      <td>1.485071</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.485071</td>\n",
       "      <td>1.010546</td>\n",
       "      <td>16.024467</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2.110685</td>\n",
       "      <td>1.811088</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.811088</td>\n",
       "      <td>1.012045</td>\n",
       "      <td>17.080070</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1.438660</td>\n",
       "      <td>2.560346</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.560346</td>\n",
       "      <td>1.010823</td>\n",
       "      <td>18.132888</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.334504</td>\n",
       "      <td>2.110450</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.110450</td>\n",
       "      <td>1.006227</td>\n",
       "      <td>19.182809</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.582934</td>\n",
       "      <td>2.136280</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.136280</td>\n",
       "      <td>1.019300</td>\n",
       "      <td>20.246623</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.437459</td>\n",
       "      <td>2.256175</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.256175</td>\n",
       "      <td>1.003276</td>\n",
       "      <td>21.291138</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(VGLM, [])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678656</td>\n",
       "      <td>0.874884</td>\n",
       "      <td>3.923145</td>\n",
       "      <td>0.874884</td>\n",
       "      <td>1.160414</td>\n",
       "      <td>1.165008</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.414047</td>\n",
       "      <td>1.717112</td>\n",
       "      <td>4.538923</td>\n",
       "      <td>1.717112</td>\n",
       "      <td>1.186307</td>\n",
       "      <td>2.544521</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.418341</td>\n",
       "      <td>3.792157</td>\n",
       "      <td>5.522690</td>\n",
       "      <td>3.792157</td>\n",
       "      <td>1.153045</td>\n",
       "      <td>3.734285</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.539731</td>\n",
       "      <td>8.433905</td>\n",
       "      <td>6.319973</td>\n",
       "      <td>8.433905</td>\n",
       "      <td>1.148081</td>\n",
       "      <td>4.940284</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714036</td>\n",
       "      <td>23.766892</td>\n",
       "      <td>5.523155</td>\n",
       "      <td>23.766892</td>\n",
       "      <td>1.503221</td>\n",
       "      <td>6.509665</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.642308</td>\n",
       "      <td>22.860257</td>\n",
       "      <td>6.727906</td>\n",
       "      <td>22.860257</td>\n",
       "      <td>1.196568</td>\n",
       "      <td>7.745179</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11.930851</td>\n",
       "      <td>9.094769</td>\n",
       "      <td>8.730463</td>\n",
       "      <td>9.094769</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>8.983688</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5.657396</td>\n",
       "      <td>4.126839</td>\n",
       "      <td>5.754077</td>\n",
       "      <td>4.126839</td>\n",
       "      <td>1.137084</td>\n",
       "      <td>10.172087</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.340365</td>\n",
       "      <td>24.617547</td>\n",
       "      <td>inf</td>\n",
       "      <td>24.617547</td>\n",
       "      <td>1.155110</td>\n",
       "      <td>11.368080</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.185027</td>\n",
       "      <td>31.005984</td>\n",
       "      <td>inf</td>\n",
       "      <td>31.005984</td>\n",
       "      <td>1.137522</td>\n",
       "      <td>12.547572</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.163392</td>\n",
       "      <td>15.614115</td>\n",
       "      <td>inf</td>\n",
       "      <td>15.614115</td>\n",
       "      <td>1.139008</td>\n",
       "      <td>13.740316</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>bgmm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(MLP, [10])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch       loss  valid_loss  test_loss  decision_loss  \\\n",
       "0     1      1   0.969458    1.896931   2.332096       1.896931   \n",
       "1     1      2   1.030030    1.959911   2.541596       1.959911   \n",
       "2     1      3   1.079324    1.995050   2.690020       1.995050   \n",
       "3     1      4   1.221408    1.663102   2.928188       1.663102   \n",
       "4     1      5   1.168919    2.618845   3.449633       2.618845   \n",
       "5     1      6   1.415992    2.093991        inf       2.093991   \n",
       "6     1      7   1.626374    1.941715        inf       1.941715   \n",
       "7     1      8   2.603916    1.938419        inf       1.938419   \n",
       "8     1      9   1.306061    1.540836        inf       1.540836   \n",
       "9     1     10   1.133800    1.845853        inf       1.845853   \n",
       "10    1     11   1.560200    1.861353        inf       1.861353   \n",
       "11    1     12   1.818080    1.967659        inf       1.967659   \n",
       "12    1     13   1.418223    1.500050        inf       1.500050   \n",
       "13    1     14   1.228807    1.875615        inf       1.875615   \n",
       "14    1     15   1.618656    1.485071        inf       1.485071   \n",
       "15    1     16   2.110685    1.811088        inf       1.811088   \n",
       "16    1     17   1.438660    2.560346        inf       2.560346   \n",
       "17    1     18   1.334504    2.110450        inf       2.110450   \n",
       "18    1     19   1.582934    2.136280        inf       2.136280   \n",
       "19    1     20   1.437459    2.256175        inf       2.256175   \n",
       "20    2      1   0.678656    0.874884   3.923145       0.874884   \n",
       "21    2      2   0.414047    1.717112   4.538923       1.717112   \n",
       "22    2      3   0.418341    3.792157   5.522690       3.792157   \n",
       "23    2      4   0.539731    8.433905   6.319973       8.433905   \n",
       "24    2      5   0.714036   23.766892   5.523155      23.766892   \n",
       "25    2      6   1.642308   22.860257   6.727906      22.860257   \n",
       "26    2      7  11.930851    9.094769   8.730463       9.094769   \n",
       "27    2      8   5.657396    4.126839   5.754077       4.126839   \n",
       "28    2      9   0.340365   24.617547        inf      24.617547   \n",
       "29    2     10   0.185027   31.005984        inf      31.005984   \n",
       "30    2     11   0.163392   15.614115        inf      15.614115   \n",
       "\n",
       "    epoch duration  run duration     lr  batch_size likelihood_fn  \\\n",
       "0         1.131365      1.136512  0.005         128          bgmm   \n",
       "1         1.059794      2.405536  0.005         128          bgmm   \n",
       "2         1.011632      3.446845  0.005         128          bgmm   \n",
       "3         1.027108      4.499626  0.005         128          bgmm   \n",
       "4         1.013980      5.555817  0.005         128          bgmm   \n",
       "5         1.010513      6.606770  0.005         128          bgmm   \n",
       "6         0.975957      7.614655  0.005         128          bgmm   \n",
       "7         1.011184      8.656074  0.005         128          bgmm   \n",
       "8         1.022666      9.712116  0.005         128          bgmm   \n",
       "9         1.008887     10.773441  0.005         128          bgmm   \n",
       "10        1.018849     11.826798  0.005         128          bgmm   \n",
       "11        1.022380     12.879641  0.005         128          bgmm   \n",
       "12        1.007361     13.923045  0.005         128          bgmm   \n",
       "13        1.016274     14.976663  0.005         128          bgmm   \n",
       "14        1.010546     16.024467  0.005         128          bgmm   \n",
       "15        1.012045     17.080070  0.005         128          bgmm   \n",
       "16        1.010823     18.132888  0.005         128          bgmm   \n",
       "17        1.006227     19.182809  0.005         128          bgmm   \n",
       "18        1.019300     20.246623  0.005         128          bgmm   \n",
       "19        1.003276     21.291138  0.005         128          bgmm   \n",
       "20        1.160414      1.165008  0.005         128          bgmm   \n",
       "21        1.186307      2.544521  0.005         128          bgmm   \n",
       "22        1.153045      3.734285  0.005         128          bgmm   \n",
       "23        1.148081      4.940284  0.005         128          bgmm   \n",
       "24        1.503221      6.509665  0.005         128          bgmm   \n",
       "25        1.196568      7.745179  0.005         128          bgmm   \n",
       "26        1.186923      8.983688  0.005         128          bgmm   \n",
       "27        1.137084     10.172087  0.005         128          bgmm   \n",
       "28        1.155110     11.368080  0.005         128          bgmm   \n",
       "29        1.137522     12.547572  0.005         128          bgmm   \n",
       "30        1.139008     13.740316  0.005         128          bgmm   \n",
       "\n",
       "    dropout_rate  k   model_arch  \n",
       "0              0  0   (VGLM, [])  \n",
       "1              0  0   (VGLM, [])  \n",
       "2              0  0   (VGLM, [])  \n",
       "3              0  0   (VGLM, [])  \n",
       "4              0  0   (VGLM, [])  \n",
       "5              0  0   (VGLM, [])  \n",
       "6              0  0   (VGLM, [])  \n",
       "7              0  0   (VGLM, [])  \n",
       "8              0  0   (VGLM, [])  \n",
       "9              0  0   (VGLM, [])  \n",
       "10             0  0   (VGLM, [])  \n",
       "11             0  0   (VGLM, [])  \n",
       "12             0  0   (VGLM, [])  \n",
       "13             0  0   (VGLM, [])  \n",
       "14             0  0   (VGLM, [])  \n",
       "15             0  0   (VGLM, [])  \n",
       "16             0  0   (VGLM, [])  \n",
       "17             0  0   (VGLM, [])  \n",
       "18             0  0   (VGLM, [])  \n",
       "19             0  0   (VGLM, [])  \n",
       "20             0  0  (MLP, [10])  \n",
       "21             0  0  (MLP, [10])  \n",
       "22             0  0  (MLP, [10])  \n",
       "23             0  0  (MLP, [10])  \n",
       "24             0  0  (MLP, [10])  \n",
       "25             0  0  (MLP, [10])  \n",
       "26             0  0  (MLP, [10])  \n",
       "27             0  0  (MLP, [10])  \n",
       "28             0  0  (MLP, [10])  \n",
       "29             0  0  (MLP, [10])  \n",
       "30             0  0  (MLP, [10])  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m st_test, predictions, importances \u001b[38;5;241m=\u001b[39m \u001b[43mmultirun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43msplit_by\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequential_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_run\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSUSHIWAT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/upper-indus-prec-bc/utils.py:981\u001b[0m, in \u001b[0;36mmultirun\u001b[0;34m(data, predictors, params, epochs, split_by, sequential_samples, sample_threshold, n_samples, best_by, use_device, load_run, feature_attribution, save_to, experiment_label)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (epochs):\n\u001b[1;32m    979\u001b[0m     m\u001b[38;5;241m.\u001b[39mbegin_epoch()\n\u001b[0;32m--> 981\u001b[0m     train_loss, val_loss, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mprint_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_by \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: decision_loss \u001b[38;5;241m=\u001b[39m val_loss\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m best_by \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: decision_loss \u001b[38;5;241m=\u001b[39m train_loss\n",
      "File \u001b[0;32m~/repos/upper-indus-prec-bc/utils.py:128\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, train_loader, valid_loader, epoch, test_loader, print_progress)\u001b[0m\n\u001b[1;32m    124\u001b[0m test_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (predictors, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    130\u001b[0m     predictors \u001b[38;5;241m=\u001b[39m predictors\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    131\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/torch/utils/data/dataset.py:188\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/torch/utils/data/dataset.py:188\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "st_test, predictions, importances = multirun(data, CONFIG.predictors, CONFIG.params, CONFIG.epochs, \n",
    "                                split_by = 'station', sequential_samples = False, load_run = None, experiment_label='SUSHIWAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cols = [f'sample_{i}' for i in range(CONFIG.n_samples)]\n",
    "add_cols = []\n",
    "columns = ['Prec','wrf_prcp','wrf_bc_prcp','precip_norris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_experiments/None/predictions.pkl', 'rb') as handle:\n",
    "#     b = pickle.load(handle)\n",
    "\n",
    "# with open('_experiments/magali/predictions.pkl', 'rb') as handle:\n",
    "#     a = pickle.load(handle)\n",
    "    \n",
    "# a.update(b)\n",
    "# a.update(predictions)\n",
    "\n",
    "# predictions = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predictions.keys(): \n",
    "    for k,v in predictions[p].items():\n",
    "        v['wrf_prcp'] = v['precip_norris'] \n",
    "        v['wrf_bc_prcp'] = v['precip_norris'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGLM_[]_bgmm_B=128_D=0                   0.574\n",
      "MLP_[10]_bgmm_B=128_D=0                  0.589\n",
      "SimpleRNN_[10]_bgmm_B=128_D=0            0.427\n"
     ]
    }
   ],
   "source": [
    "for k,v in predictions.items():\n",
    "    print(f\"{k : <40} {v['k_all'].BS.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import QS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_QS(predictions, quantile = 0.5): \n",
    "    for k,v in predictions.items(): \n",
    "        p = v['k_all']\n",
    "        p[f'QS_quantile_{quantile}'] = quantile\n",
    "        likelihood = k.split('_')[2]\n",
    "        p[f'QS_sample_{quantile}'] = p.apply(sample_apply, axis=1, args=(likelihood, 10000, f'QS_quantile_{quantile}'))\n",
    "        p[f'QS_{quantile}'] = p.apply(QS, axis=1, args=('QS_sample', 'Prec', quantile))\n",
    "        print(f'Completed {k} {quantile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed VGLM_[]_bgmm_B=128_D=0 0.1\n",
      "Completed MLP_[10]_bgmm_B=128_D=0 0.1\n",
      "Completed SimpleRNN_[10]_bgmm_B=128_D=0 0.1\n",
      "Completed VGLM_[]_bgmm_B=128_D=0 0.25\n",
      "Completed MLP_[10]_bgmm_B=128_D=0 0.25\n",
      "Completed SimpleRNN_[10]_bgmm_B=128_D=0 0.25\n",
      "Completed VGLM_[]_bgmm_B=128_D=0 0.5\n",
      "Completed MLP_[10]_bgmm_B=128_D=0 0.5\n",
      "Completed SimpleRNN_[10]_bgmm_B=128_D=0 0.5\n",
      "Completed VGLM_[]_bgmm_B=128_D=0 0.75\n",
      "Completed MLP_[10]_bgmm_B=128_D=0 0.75\n",
      "Completed SimpleRNN_[10]_bgmm_B=128_D=0 0.75\n",
      "Completed VGLM_[]_bgmm_B=128_D=0 0.9\n",
      "Completed MLP_[10]_bgmm_B=128_D=0 0.9\n",
      "Completed SimpleRNN_[10]_bgmm_B=128_D=0 0.9\n",
      "Completed VGLM_[]_bgmm_B=128_D=0 0.95\n",
      "Completed MLP_[10]_bgmm_B=128_D=0 0.95\n",
      "Completed SimpleRNN_[10]_bgmm_B=128_D=0 0.95\n"
     ]
    }
   ],
   "source": [
    "compute_QS(predictions, quantile = 0.10)\n",
    "compute_QS(predictions, quantile = 0.25)\n",
    "compute_QS(predictions, quantile = 0.50)\n",
    "compute_QS(predictions, quantile = 0.75)\n",
    "compute_QS(predictions, quantile = 0.90)\n",
    "compute_QS(predictions, quantile = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in predictions.items():\n",
    "#     print(f\"{k : <40} {v['k_all']['QS_0.1'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in predictions.items():\n",
    "#     print(f\"{k : <40} {v['k_all']['QS_0.25'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in predictions.items():\n",
    "#     print(f\"{k : <40} {v['k_all']['QS_0.5'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in predictions.items():\n",
    "#     print(f\"{k : <40} {v['k_all']['QS_0.75'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in predictions.items():\n",
    "#     print(f\"{k : <40} {v['k_all']['QS_0.9'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in predictions.items():\n",
    "#     print(f\"{k : <40} {v['k_all']['QS_0.95'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGLM_[]_bgmm_B=128_D=0\n",
      "MLP_[10]_bgmm_B=128_D=0\n",
      "SimpleRNN_[10]_bgmm_B=128_D=0\n",
      "Model                          JFM mean    JFM median    AM mean    AM median    JJAS mean    JJAS median    OND mean    OND median\n",
      "-----------------------------  ----------  ------------  ---------  -----------  -----------  -------------  ----------  ------------\n",
      "Bann                           0.0757      0.0573        0.1029     0.0567       0.1522       0.0601         0.1348      0.0584\n",
      "BannCorr                       0.0757      0.0573        0.1029     0.0567       0.1522       0.0601         0.1348      0.0584\n",
      "Norr                           0.0757      0.0573        0.1029     0.0567       0.1522       0.0601         0.1348      0.0584\n",
      "VGLM_[]_bgmm_B=128_D=0         0.2198      0.0585        0.1215     0.0920       0.0566       0.0509         0.1680      0.0583\n",
      "MLP_[10]_bgmm_B=128_D=0        0.2107      0.0607        0.2306     0.0692       0.0548       0.0246         0.1978      0.0492\n",
      "SimpleRNN_[10]_bgmm_B=128_D=0  0.0632      0.0357        0.0714     0.0560       0.0695       0.0417         0.1072      0.0387\n"
     ]
    }
   ],
   "source": [
    "table_of_predictions_ks_test(predictions, CONFIG.seasons, columns, sample_cols, add_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          JFM mean    JFM median    AM mean    AM median    JJAS mean    JJAS median    OND mean    OND median\n",
      "-----------------------------  ----------  ------------  ---------  -----------  -----------  -------------  ----------  ------------\n",
      "Prec                           0.00        0.00          0.00       0.00         0.00         0.00           0.00        0.00\n",
      "wrf_prcp                       0.23        0.18          0.38       0.35         0.21         0.18           0.39        0.34\n",
      "wrf_bc_prcp                    0.23        0.18          0.38       0.35         0.21         0.18           0.39        0.34\n",
      "precip_norris                  0.23        0.18          0.38       0.35         0.21         0.18           0.39        0.34\n",
      "VGLM_[]_bgmm_B=128_D=0         0.25        0.21          0.36       0.32         0.20         0.15           0.40        0.30\n",
      "MLP_[10]_bgmm_B=128_D=0        0.24        0.18          0.29       0.25         0.20         0.16           0.41        0.33\n",
      "SimpleRNN_[10]_bgmm_B=128_D=0  0.24        0.21          0.26       0.22         0.32         0.29           0.48        0.46\n"
     ]
    }
   ],
   "source": [
    "table_of_predictions_for_metric(predictions, CONFIG.seasons, columns, CONFIG.n_samples, sample_cols, add_cols, metric = 'smape', prefix='smape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          JFM mean    JFM median    AM mean    AM median    JJAS mean    JJAS median    OND mean    OND median\n",
      "-----------------------------  ----------  ------------  ---------  -----------  -----------  -------------  ----------  ------------\n",
      "Prec                           0.00        0.00          0.00       0.00         0.00         0.00           0.00        0.00\n",
      "wrf_prcp                       14.21       10.00         12.79      12.00        32.95        34.00          7.52        5.50\n",
      "wrf_bc_prcp                    14.21       10.00         12.79      12.00        32.95        34.00          7.52        5.50\n",
      "precip_norris                  14.21       10.00         12.79      12.00        32.95        34.00          7.52        5.50\n",
      "VGLM_[]_bgmm_B=128_D=0         5.74        4.60          5.85       4.30         10.32        7.70           5.16        4.30\n",
      "MLP_[10]_bgmm_B=128_D=0        5.86        4.80          4.77       3.70         10.84        8.80           4.73        3.55\n",
      "SimpleRNN_[10]_bgmm_B=128_D=0  10.17       9.60          6.36       5.10         11.04        9.40           18.46       19.70\n"
     ]
    }
   ],
   "source": [
    "table_of_predictions_for_metric(predictions, CONFIG.seasons, columns, CONFIG.n_samples, sample_cols, add_cols, metric = 'edd', prefix='edd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          JFM mean    JFM median    AM mean    AM median    JJAS mean    JJAS median    OND mean    OND median\n",
      "-----------------------------  ----------  ------------  ---------  -----------  -----------  -------------  ----------  ------------\n",
      "Prec                           0.00        0.00          0.00       0.00         0.00         0.00           0.00        0.00\n",
      "wrf_prcp                       74.51       55.94         53.95      44.58        293.28       191.28         33.85       19.84\n",
      "wrf_bc_prcp                    74.51       55.94         53.95      44.58        293.28       191.28         33.85       19.84\n",
      "precip_norris                  74.51       55.94         53.95      44.58        293.28       191.28         33.85       19.84\n",
      "VGLM_[]_bgmm_B=128_D=0         84.24       63.04         51.28      37.37        273.26       203.65         44.41       37.07\n",
      "MLP_[10]_bgmm_B=128_D=0        86.69       62.62         45.33      37.92        276.16       187.20         46.52       38.32\n",
      "SimpleRNN_[10]_bgmm_B=128_D=0  87.43       57.98         43.57      32.23        417.48       192.75         71.02       78.97\n"
     ]
    }
   ],
   "source": [
    "table_of_predictions_for_metric(predictions, CONFIG.seasons, columns, CONFIG.n_samples, sample_cols, add_cols, metric = 'ae', prefix='ae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_of_predictions_for_metric(predictions, CONFIG.seasons, columns, CONFIG.n_samples, sample_cols, add_cols, metric = 'se', prefix='se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('results.csv')\n",
    "\n",
    "b = a.groupby(['k','run']).agg({'valid_loss': 'min', \n",
    "                                 'model_arch': 'first', \n",
    "                                 'likelihood_fn': 'first',\n",
    "                                 'lr':'first',\n",
    "                                 'batch_size':'first',\n",
    "                                 'dropout_rate':'first',\n",
    "                               })\n",
    "\n",
    "c = b.groupby(['run']).agg({'valid_loss': 'mean', \n",
    "                        'model_arch': 'first', \n",
    "                        'likelihood_fn': 'first',\n",
    "                        'lr':'first',\n",
    "                        'batch_size':'first',\n",
    "                        'dropout_rate':'first',\n",
    "                         }\n",
    "                   ).sort_values('valid_loss').reset_index()\n",
    "\n",
    "c.groupby(['model_arch',\n",
    "           'likelihood_fn',\n",
    "           'lr',\n",
    "           'batch_size',\n",
    "           'dropout_rate',\n",
    "           ]).agg({'valid_loss': 'mean'}\n",
    "                   ).sort_values('valid_loss').reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bcdp]",
   "language": "python",
   "name": "conda-env-bcdp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6f7d0f407510cc81edbbb8fa0d61f79bb70425ade7d5a8e5edb94832bf1e351"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
