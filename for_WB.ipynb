{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/fdm/fdm.py:38: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  coefs = mat.inv()[:, deriv] * np.math.factorial(deriv)\n",
      "/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/fdm/fdm.py:44: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  / np.math.factorial(order)\n",
      "/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/fdm/fdm.py:38: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  coefs = mat.inv()[:, deriv] * np.math.factorial(deriv)\n",
      "/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/fdm/fdm.py:44: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  / np.math.factorial(order)\n",
      "/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/data/hpcdata/users/marron31/conda-envs/bcdp/lib/python3.9/site-packages/captum/attr/_utils/visualization.py:15: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from stheno.torch import B, GP, EQ, Normal, Measure, Matern12, Matern32, Matern52\n",
    "\n",
    "from models import MLP\n",
    "from utils import RunningAverage\n",
    "\n",
    "from elbo import ApproximatePosterior\n",
    "from gp_mlp import forward_backward_pass, UpperIndusDataset\n",
    "\n",
    "# Detect device.\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let all of Stheno run on that device.\n",
    "B.on_device(device).__enter__()\n",
    "    \n",
    "# B.epsilon is the default value for the diagonal jitter of the matrix\n",
    "B.epsilon = 1e-4  # Needs to be relatively high for `float32`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE INPUT AND OUTPUT VARIABLES (PREDICTORS AND PREDICTANDS)\n",
    "\n",
    "predictant = ['Prec']\n",
    "predictors = [\n",
    "              'X','Y','Z', \n",
    "              'RAIN',\n",
    "              'doy_sin', 'doy_cos', \n",
    "              'W500', 'RH2', 'U500', 'V10', \n",
    "              'RH500', 'U10', 'V500', \n",
    "              'T2MIN', 'T2', 'T2MAX'\n",
    "                 ]\n",
    "    \n",
    "\n",
    "# DEFINE TRAINING STATIONS\n",
    "train_stations = ['ABO', 'AHO', 'AIR', 'ALV', 'APT', 'ARO', 'AUB', 'AVA', 'AVB', 'BAC', 'BAL', 'BEA', 'BEC', 'BEGTH', 'BEGWA', 'BEH', 'BEHAK', 'BEKSE', 'BERIF', 'BES', 'BEV', 'BIN', 'BIV', 'BLA', 'BRA', 'BRW', 'BSP', 'BSW', 'CAV', 'CDF', 'CHA', 'CHB', 'CHD', 'CHM', 'CHW', 'CIM', 'COV', 'CTA', 'CTO', 'CUE', 'DAV', 'DIB', 'DIS', 'DLBAL', 'DLFEB', 'DLZUG', 'DMA', 'DOL', 'EIT', 'ENG', 'ERN', 'EVL', 'EVO', 'FIL', 'FIO', 'FIT', 'FLI', 'FRE', 'GEN', 'GOA', 'GRC', 'GRH', 'GSB', 'GSG', 'GST', 'GTT', 'GWA', 'HER', 'HIR', 'HOE', 'INF', 'IYDEO', 'IYDEU', 'IYMMR', 'IYMUW', 'IYPEN', 'IYPFE', 'IYPFI', 'IYPLI', 'IYPRU', 'IYREI', 'IYRID', 'IYROT', 'IYSMG', 'IYSMT', 'IYSUL', 'IYSUM', 'IYSVP', 'IYSWA', 'IYTER', 'IYTOB', 'IYULT', 'IYVAA', 'IYVAL', 'IYWEL', 'IYWOL', 'KLA', 'KRO', 'KSE', 'LBA', 'LEH', 'LEU', 'LOC', 'LOE', 'MAL', 'MAT', 'MAU', 'MLS', 'MOD', 'MSO', 'MST', 'MTE', 'MUE', 'MUS', 'MVE', 'NABCHA', 'NABDAV', 'NAP', 'NEB', 'OBI', 'OBW', 'PDM', 'PIG', 'PIL', 'PLF', 'PON', 'PSB', 'PUD', 'REC', 'ROB', 'ROE', 'ROG', 'RUM', 'SAB', 'SAE', 'SAF', 'SAM', 'SAN', 'SAP', 'SAS', 'SBA', 'SBE', 'SCU', 'SDO', 'SED', 'SEP', 'SGD', 'SIA', 'SIM', 'SLFAM2', 'SLFEM2', 'SLFFIS', 'SLFGL2', 'SLFMEI', 'SLFOBM', 'SLFSA3', 'SLFSC2', 'SLFSC3', 'SLFTU2', 'SLFUR2', 'SLFURS', 'SNE', 'SOG', 'SRL', 'STP', 'SVG', 'SWA', 'TIBED', 'TIBIA', 'TICOL', 'TIFUS', 'TIOLI', 'TST', 'UNS', 'URB', 'VDLSP', 'VDSEP', 'VEL', 'VIO', 'VRI', 'VSANZ', 'VSARO', 'VSBRI', 'VSCHY', 'VSDUR', 'VSEMO', 'VSFIN', 'VSGDX', 'VSJEI', 'VSMAT', 'VSSAB', 'VSSTA', 'VST', 'VSVER', 'WAW', 'WET', 'ZER', 'ZEV', 'ZNZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates (but in this notebook we only use data for year 2000)\n",
    "start=\"1900-01-01\"\n",
    "end=\"2020-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for year 2000\n",
    "TRAIN_PATH = 'alps_2000.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_dataset = UpperIndusDataset(TRAIN_PATH, start, end, predictant, predictors, stations=train_stations)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=ds_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_GP_dims = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3603\n"
     ]
    }
   ],
   "source": [
    "# This is the MLP used in the GP-MLP model\n",
    "model = MLP(in_channels= len(predictors)+1,#-num_GP_dims, \n",
    "            hidden_channels=[50,50], \n",
    "            likelihood_fn='bgmm', # 'gamma', 'ggmm', bgmm', 'b2gmm', 'b2sgmm'\n",
    "            dropout_rate=0,\n",
    "           )\n",
    "\n",
    "print(f'Number of parameters: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (hidden): ModuleList(\n",
       "    (0): Linear(in_features=17, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=50, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_progress = True\n",
    "plot_x_ind = True\n",
    "validate_flag = True\n",
    "f_marginal_flag = False\n",
    "mc_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ds_dataset.st\n",
    "coords_train_stations = st.groupby('Station').mean()[predictors[:num_GP_dims]].values\n",
    "\n",
    "x_ind_stations = coords_train_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inducing points are fixed to the station locations\n",
    "x_ind = torch.tensor(x_ind_stations, dtype=torch.float32).detach().requires_grad_(False).to(device)\n",
    "\n",
    "num_ind_points = len(x_ind)\n",
    "n = len(st)\n",
    "\n",
    "ls = torch.nn.Parameter(torch.tensor(2, dtype=torch.float32, requires_grad=True).to(device))\n",
    "\n",
    "with Measure() as prior:\n",
    "#     f = GP(EQ().stretch(ls))\n",
    "    f = GP(Matern12().stretch(ls))\n",
    "    \n",
    "q = ApproximatePosterior(num_ind_points, use_device=device) # q is the approximate posterior\n",
    "\n",
    "# optimizer = torch.optim.Adam(list(model.parameters())+list(q.parameters()), lr=10e-4)\n",
    "optimizer = torch.optim.Adam(list(model.parameters())+list(q.parameters())+[ls], lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_past = 0\n",
    "\n",
    "train_loss, train_loglik, train_kl, train_nll = [], [], [], []\n",
    "val_loss, val_loglik, val_kl, val_nll = [], [], [], []\n",
    "\n",
    "test_loss, test_loglik, test_kl, test_nll  = [], [], [], []\n",
    "\n",
    "train_loss_batch, train_loglik_batch, train_kl_batch, train_nll_batch = RunningAverage(), RunningAverage(), RunningAverage(), RunningAverage()\n",
    "val_loss_batch, val_loglik_batch, val_kl_batch, val_nll_batch = RunningAverage(), RunningAverage(), RunningAverage(),RunningAverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 1, 1.00\n",
      "Train epoch  1: -elbo: 4.730 | kl: 88154.087 | -recon: 3.284 | nll: 3.208 -- time: 2.75\n",
      "GP lengthscale: 1.9770554304122925\n",
      "Memory used: 2, 0.30\n",
      "Train epoch  2: -elbo: 3.741 | kl: 84266.560 | -recon: 2.358 | nll: 2.314 -- time: 1.37\n",
      "GP lengthscale: 1.9543564319610596\n",
      "Memory used: 3, 0.49\n",
      "Train epoch  3: -elbo: 3.477 | kl: 80505.113 | -recon: 2.157 | nll: 2.133 -- time: 1.53\n",
      "GP lengthscale: 1.9320135116577148\n",
      "Memory used: 4, 0.52\n",
      "Train epoch  4: -elbo: 3.341 | kl: 76887.608 | -recon: 2.079 | nll: 2.061 -- time: 1.38\n",
      "GP lengthscale: 1.9100332260131836\n",
      "Memory used: 5, 0.61\n",
      "Train epoch  5: -elbo: 3.231 | kl: 73347.646 | -recon: 2.027 | nll: 2.011 -- time: 1.36\n",
      "GP lengthscale: 1.8884611129760742\n",
      "Memory used: 6, 0.67\n",
      "Train epoch  6: -elbo: 3.130 | kl: 70040.603 | -recon: 1.981 | nll: 1.968 -- time: 1.38\n",
      "GP lengthscale: 1.8672754764556885\n",
      "Memory used: 7, 0.69\n",
      "Train epoch  7: -elbo: 3.042 | kl: 66818.965 | -recon: 1.945 | nll: 1.934 -- time: 1.37\n",
      "GP lengthscale: 1.846492886543274\n",
      "Memory used: 8, 0.72\n",
      "Train epoch  8: -elbo: 2.973 | kl: 63818.195 | -recon: 1.926 | nll: 1.917 -- time: 1.38\n",
      "GP lengthscale: 1.8260773420333862\n",
      "Memory used: 9, 0.74\n",
      "Train epoch  9: -elbo: 2.909 | kl: 60883.143 | -recon: 1.910 | nll: 1.901 -- time: 1.35\n",
      "GP lengthscale: 1.806043028831482\n",
      "Memory used: 10, 0.76\n",
      "Train epoch  10: -elbo: 2.850 | kl: 58183.657 | -recon: 1.896 | nll: 1.890 -- time: 1.35\n",
      "GP lengthscale: 1.7863656282424927\n",
      "Memory used: 11, 0.77\n",
      "Train epoch  11: -elbo: 2.803 | kl: 55575.180 | -recon: 1.891 | nll: 1.885 -- time: 1.32\n",
      "GP lengthscale: 1.767042636871338\n",
      "Memory used: 12, 0.79\n",
      "Train epoch  12: -elbo: 2.753 | kl: 53102.569 | -recon: 1.881 | nll: 1.877 -- time: 1.35\n",
      "GP lengthscale: 1.748057246208191\n",
      "Memory used: 13, 0.79\n",
      "Train epoch  13: -elbo: 2.713 | kl: 50782.255 | -recon: 1.880 | nll: 1.876 -- time: 1.34\n",
      "GP lengthscale: 1.7294037342071533\n",
      "Memory used: 14, 0.81\n",
      "Train epoch  14: -elbo: 2.669 | kl: 48557.085 | -recon: 1.873 | nll: 1.869 -- time: 1.34\n",
      "GP lengthscale: 1.7110689878463745\n",
      "Memory used: 15, 0.83\n",
      "Train epoch  15: -elbo: 2.624 | kl: 46417.757 | -recon: 1.863 | nll: 1.860 -- time: 1.36\n",
      "GP lengthscale: 1.6930620670318604\n",
      "Memory used: 16, 0.83\n",
      "Train epoch  16: -elbo: 2.591 | kl: 44399.869 | -recon: 1.863 | nll: 1.860 -- time: 1.34\n",
      "GP lengthscale: 1.6753724813461304\n",
      "Memory used: 17, 0.84\n",
      "Train epoch  17: -elbo: 2.554 | kl: 42495.613 | -recon: 1.856 | nll: 1.854 -- time: 1.35\n",
      "GP lengthscale: 1.6579899787902832\n",
      "Memory used: 18, 0.85\n",
      "Train epoch  18: -elbo: 2.519 | kl: 40670.269 | -recon: 1.851 | nll: 1.849 -- time: 1.35\n",
      "GP lengthscale: 1.6409027576446533\n",
      "Memory used: 19, 0.86\n",
      "Train epoch  19: -elbo: 2.485 | kl: 38926.335 | -recon: 1.846 | nll: 1.844 -- time: 1.37\n",
      "GP lengthscale: 1.624117136001587\n",
      "Memory used: 20, 0.84\n",
      "Train epoch  20: -elbo: 2.460 | kl: 37284.312 | -recon: 1.848 | nll: 1.845 -- time: 1.33\n",
      "GP lengthscale: 1.607616662979126\n",
      "Memory used: 21, 0.87\n",
      "Train epoch  21: -elbo: 2.433 | kl: 35723.742 | -recon: 1.846 | nll: 1.844 -- time: 1.34\n",
      "GP lengthscale: 1.5913742780685425\n",
      "Memory used: 22, 0.88\n",
      "Train epoch  22: -elbo: 2.398 | kl: 34227.845 | -recon: 1.837 | nll: 1.835 -- time: 1.28\n",
      "GP lengthscale: 1.5754127502441406\n",
      "Memory used: 23, 0.88\n",
      "Train epoch  23: -elbo: 2.377 | kl: 32806.563 | -recon: 1.839 | nll: 1.837 -- time: 1.31\n",
      "GP lengthscale: 1.559715747833252\n",
      "Memory used: 24, 0.88\n",
      "Train epoch  24: -elbo: 2.354 | kl: 31457.090 | -recon: 1.838 | nll: 1.836 -- time: 1.32\n",
      "GP lengthscale: 1.5442836284637451\n",
      "Memory used: 25, 0.88\n",
      "Train epoch  25: -elbo: 2.329 | kl: 30154.845 | -recon: 1.835 | nll: 1.833 -- time: 1.29\n",
      "GP lengthscale: 1.52910578250885\n",
      "Memory used: 26, 0.89\n",
      "Train epoch  26: -elbo: 2.313 | kl: 28911.009 | -recon: 1.838 | nll: 1.836 -- time: 1.30\n",
      "GP lengthscale: 1.5141886472702026\n",
      "Memory used: 27, 0.90\n",
      "Train epoch  27: -elbo: 2.287 | kl: 27745.498 | -recon: 1.832 | nll: 1.830 -- time: 1.33\n",
      "GP lengthscale: 1.499506950378418\n",
      "Memory used: 28, 0.90\n",
      "Train epoch  28: -elbo: 2.267 | kl: 26619.082 | -recon: 1.830 | nll: 1.828 -- time: 1.29\n",
      "GP lengthscale: 1.4850757122039795\n",
      "Memory used: 29, 0.90\n",
      "Train epoch  29: -elbo: 2.246 | kl: 25541.653 | -recon: 1.827 | nll: 1.825 -- time: 1.24\n",
      "GP lengthscale: 1.4708869457244873\n",
      "Memory used: 30, 0.90\n",
      "Train epoch  30: -elbo: 2.229 | kl: 24524.535 | -recon: 1.826 | nll: 1.824 -- time: 1.35\n",
      "GP lengthscale: 1.456928014755249\n",
      "Memory used: 31, 0.91\n",
      "Train epoch  31: -elbo: 2.211 | kl: 23556.153 | -recon: 1.825 | nll: 1.823 -- time: 1.26\n",
      "GP lengthscale: 1.4431849718093872\n",
      "Memory used: 32, 0.89\n",
      "Train epoch  32: -elbo: 2.191 | kl: 22635.406 | -recon: 1.820 | nll: 1.818 -- time: 1.35\n",
      "GP lengthscale: 1.4296581745147705\n",
      "Memory used: 33, 0.91\n",
      "Train epoch  33: -elbo: 2.178 | kl: 21741.911 | -recon: 1.822 | nll: 1.820 -- time: 1.36\n",
      "GP lengthscale: 1.4163395166397095\n",
      "Memory used: 34, 0.92\n",
      "Train epoch  34: -elbo: 2.163 | kl: 20896.078 | -recon: 1.820 | nll: 1.818 -- time: 1.35\n",
      "GP lengthscale: 1.4032214879989624\n",
      "Memory used: 35, 0.92\n",
      "Train epoch  35: -elbo: 2.145 | kl: 20083.496 | -recon: 1.816 | nll: 1.814 -- time: 1.35\n",
      "GP lengthscale: 1.3903230428695679\n",
      "Memory used: 36, 0.92\n",
      "Train epoch  36: -elbo: 2.128 | kl: 19313.168 | -recon: 1.811 | nll: 1.809 -- time: 1.35\n",
      "GP lengthscale: 1.3776230812072754\n",
      "Memory used: 37, 0.91\n",
      "Train epoch  37: -elbo: 2.118 | kl: 18574.134 | -recon: 1.814 | nll: 1.812 -- time: 1.34\n",
      "GP lengthscale: 1.3651201725006104\n",
      "Memory used: 38, 0.92\n",
      "Train epoch  38: -elbo: 2.106 | kl: 17866.829 | -recon: 1.813 | nll: 1.811 -- time: 1.36\n",
      "GP lengthscale: 1.3528128862380981\n",
      "Memory used: 39, 0.93\n",
      "Train epoch  39: -elbo: 2.097 | kl: 17190.749 | -recon: 1.815 | nll: 1.813 -- time: 1.34\n",
      "GP lengthscale: 1.3406914472579956\n",
      "Memory used: 40, 0.93\n",
      "Train epoch  40: -elbo: 2.077 | kl: 16543.601 | -recon: 1.806 | nll: 1.804 -- time: 1.36\n",
      "GP lengthscale: 1.3287575244903564\n",
      "Memory used: 41, 0.93\n",
      "Train epoch  41: -elbo: 2.070 | kl: 15926.215 | -recon: 1.809 | nll: 1.807 -- time: 1.34\n",
      "GP lengthscale: 1.3170039653778076\n",
      "Memory used: 42, 0.93\n",
      "Train epoch  42: -elbo: 2.058 | kl: 15337.461 | -recon: 1.807 | nll: 1.805 -- time: 1.35\n",
      "GP lengthscale: 1.3054194450378418\n",
      "Memory used: 43, 0.93\n",
      "Train epoch  43: -elbo: 2.046 | kl: 14764.601 | -recon: 1.804 | nll: 1.802 -- time: 1.35\n",
      "GP lengthscale: 1.2940115928649902\n",
      "Memory used: 44, 0.92\n",
      "Train epoch  44: -elbo: 2.041 | kl: 14225.721 | -recon: 1.807 | nll: 1.806 -- time: 1.33\n",
      "GP lengthscale: 1.2827693223953247\n",
      "Memory used: 45, 0.93\n",
      "Train epoch  45: -elbo: 2.030 | kl: 13702.534 | -recon: 1.805 | nll: 1.804 -- time: 1.35\n",
      "GP lengthscale: 1.271698236465454\n",
      "Memory used: 46, 0.94\n",
      "Train epoch  46: -elbo: 2.023 | kl: 13203.979 | -recon: 1.806 | nll: 1.805 -- time: 1.34\n",
      "GP lengthscale: 1.2607879638671875\n",
      "Memory used: 47, 0.94\n",
      "Train epoch  47: -elbo: 2.004 | kl: 12731.170 | -recon: 1.795 | nll: 1.794 -- time: 1.36\n",
      "GP lengthscale: 1.2500275373458862\n",
      "Memory used: 48, 0.94\n",
      "Train epoch  48: -elbo: 1.997 | kl: 12273.498 | -recon: 1.796 | nll: 1.794 -- time: 1.35\n",
      "GP lengthscale: 1.2394232749938965\n",
      "Memory used: 49, 0.93\n",
      "Train epoch  49: -elbo: 1.999 | kl: 11834.027 | -recon: 1.804 | nll: 1.803 -- time: 1.36\n",
      "GP lengthscale: 1.2289668321609497\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "    \n",
    "for e in range(e_past + 1, num_epochs):\n",
    "    \n",
    "    print(f\"Memory used: {e}, {(torch.cuda.memory_allocated()/torch.cuda.max_memory_allocated()):.2f}\")\n",
    "    \n",
    "    # TRAIN EPOCH    \n",
    "    model.train()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss_batch.reset()\n",
    "    train_loglik_batch.reset()\n",
    "    train_kl_batch.reset()\n",
    "    train_nll_batch.reset()\n",
    "    val_loss_batch.reset()\n",
    "    val_loglik_batch.reset()\n",
    "    val_kl_batch.reset()\n",
    "    val_nll_batch.reset()\n",
    "\n",
    "    n = train_dataloader.dataset.n\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        inputs = inputs.to(device) # inputs [batch_size, num_predictors, num_stations]\n",
    "        labels = labels.to(device) # labels [batch_size, num_stations]\n",
    "\n",
    "        elbo, recon, kl, num_points, nll = forward_backward_pass(inputs, labels, n, model, optimizer, q, f, x_ind, \n",
    "                                                            inducing_points=True, backward=True, f_marginal=f_marginal_flag, n_samples=mc_samples,\n",
    "                                                            num_GP_dims=num_GP_dims, remove_from_inputs=False)\n",
    "\n",
    "        # Keep track of loss terms\n",
    "        train_loss_batch.update(-elbo.item())\n",
    "        train_loglik_batch.update(-recon.item())\n",
    "        train_kl_batch.update(kl.item())\n",
    "        train_nll_batch.update(nll.item()/num_points.item())\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    if print_progress:\n",
    "        print(f'Train epoch  {e}: -elbo: {train_loss_batch.avg:.3f} | kl: {train_kl_batch.avg:.3f} | -recon: {train_loglik_batch.avg:.3f} | nll: {train_nll_batch.avg:.3f} -- time: {elapsed:.2f}')\n",
    "        print(f'GP lengthscale: {ls.item()}')\n",
    "\n",
    "    # Add average batch loss terms to lists\n",
    "    train_loss.append(train_loss_batch.avg)\n",
    "    train_loglik.append(train_loglik_batch.avg)\n",
    "    train_kl.append(train_kl_batch.avg)\n",
    "    train_nll.append(train_nll_batch.avg)\n",
    "    \n",
    "# VALIDATION REMOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m validation_vars \u001b[38;5;241m=\u001b[39m [val_loss, val_loglik, val_kl, val_nll]\n\u001b[1;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative ELBO\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative log likelihood term\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKL divergence term\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(axes\u001b[38;5;241m.\u001b[39mflatten()):\n\u001b[1;32m      8\u001b[0m     ax\u001b[38;5;241m.\u001b[39mplot(train_vars[i], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "train_vars = [train_loss, train_loglik, train_kl, train_nll] \n",
    "validation_vars = [val_loss, val_loglik, val_kl, val_nll]\n",
    "\n",
    "labels = ['Negative ELBO','Negative log likelihood term','KL divergence term','NLL']\n",
    "\n",
    "fig, axes = plt.subplots(4,1, figsize=(10,10))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    ax.plot(train_vars[i], label='train')\n",
    "    ax.plot(validation_vars[i], label='val')\n",
    "#     ax.set_title(f'{labels[i]} | best: {np.min(train_vars[i]):.2f}')\n",
    "    ax.set_ylabel(f'{labels[i]}', fontsize=14)\n",
    "    ax.set_xlabel('Epoch', fontsize=14)\n",
    "    ax.set_xticks(np.arange(0, num_epochs))\n",
    "#     ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bcdp]",
   "language": "python",
   "name": "conda-env-bcdp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
